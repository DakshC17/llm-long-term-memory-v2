{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e22d06d2",
   "metadata": {},
   "source": [
    "# Vector Database Setup and Exploration\n",
    "\n",
    "This notebook explores ChromaDB for our LLM long-term memory project.\n",
    "\n",
    "## Goals:\n",
    "- Install and setup ChromaDB\n",
    "- Create a simple collection\n",
    "- Add some sample data\n",
    "- Test basic similarity search\n",
    "- Understand how embeddings work\n",
    "\n",
    "## What we're building:\n",
    "A memory system that stores conversations and retrieves similar past interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "163f33c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "ChromaDB version: 1.0.20\n",
      "Current time: 2025-08-30 12:59:21.019075\n"
     ]
    }
   ],
   "source": [
    "# Here we are importing usefull libraries to start with..\n",
    "import chromadb\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "#lets check if imported\n",
    "\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"ChromaDB version: {chromadb.__version__}\")\n",
    "print(f\"Current time: {datetime.now()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70d0c88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new collection!\n",
      "Collection name: conversation_memory\n",
      "Collection count: 0\n",
      "Ready to store memories!\n"
     ]
    }
   ],
   "source": [
    "# we will create a chromadb client now\n",
    "client = chromadb.Client()\n",
    "\n",
    "# Try to get existing collection or create new one\n",
    "try:\n",
    "    collection = client.get_collection(name=\"conversation_memory\")\n",
    "    print(\"Found existing collection!\")\n",
    "except:\n",
    "    collection = client.create_collection(\n",
    "        name=\"conversation_memory\",\n",
    "        metadata={\"description\": \"Stores conversation history for LLM memory and have a large context over conversations.\"}\n",
    "    )\n",
    "    print(\"Created new collection!\")\n",
    "\n",
    "print(f\"Collection name: {collection.name}\")\n",
    "print(f\"Collection count: {collection.count()}\")\n",
    "print(\"Ready to store memories!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efe39d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dakshchoudhary/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz: 100%|██████████| 79.3M/79.3M [06:22<00:00, 217kiB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 5 conversations to memory!\n",
      "Total conversations in collection: 5\n"
     ]
    }
   ],
   "source": [
    "# Now we will try to add some sample conversation so that we can use for testing and creating our agent...\n",
    "sample_conversations = [\n",
    "    \"User asked about machine learning basics and showed interest in neural networks\",\n",
    "    \"User wants to learn Python programming and mentioned they are a beginner\",\n",
    "    \"Discussion about building a web scraping project using BeautifulSoup\",\n",
    "    \"User asked for help with data visualization using matplotlib and pandas\",\n",
    "    \"Conversation about setting up a virtual environment for Python projects\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "#lets map with simple ids\n",
    "for i, conversation in enumerate(sample_conversations):\n",
    "    collection.add(\n",
    "        documents=[conversation],\n",
    "        ids=[f\"conv_{i+1}\"]\n",
    "    )\n",
    "\n",
    "print(f\"Added {len(sample_conversations)} conversations to memory!\")\n",
    "print(f\"Total conversations in collection: {collection.count()}\")\n",
    "\n",
    "\n",
    "#it will take few minutes to load the conversations\n",
    "#sentence transformer will be downloaded. it will convert text into 384 dimensional vectors \n",
    "#it will be great for semantic similarity search\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fa99450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 'I want to learn programming'\n",
      "\n",
      "Most similar past conversations:\n",
      "1. User wants to learn Python programming and mentioned they are a beginner\n",
      "   Similarity score: 0.243\n",
      "\n",
      "2. User asked about machine learning basics and showed interest in neural networks\n",
      "   Similarity score: -0.437\n",
      "\n",
      "3. Conversation about setting up a virtual environment for Python projects\n",
      "   Similarity score: -0.546\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing will be done now \n",
    "query = \"I want to learn programming\"   #a query we initialised for testing\n",
    "\n",
    "\n",
    "# Search for similar conversations\n",
    "results = collection.query(\n",
    "    query_texts=[query],\n",
    "    n_results=3  #  it will Get the top 3 most similar conversations\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Query: '{query}'\")\n",
    "print(\"\\nMost similar past conversations:\")\n",
    "for i, (doc, distance) in enumerate(zip(results['documents'][0], results['distances'][0])):\n",
    "    print(f\"{i+1}. {doc}\")\n",
    "    print(f\"   Similarity score: {1-distance:.3f}\\n\")\n",
    "\n",
    "\n",
    "##this will show you the result of similar searching \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e5584ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 'help me with data analysis and charts'\n",
      "\n",
      "Most similar past conversations:\n",
      "1. User asked for help with data visualization using matplotlib and pandas\n",
      "   Similarity score: 0.164\n",
      "\n",
      "2. User asked about machine learning basics and showed interest in neural networks\n",
      "   Similarity score: -0.592\n",
      "\n",
      "3. Discussion about building a web scraping project using BeautifulSoup\n",
      "   Similarity score: -0.671\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lets test it for another query and see how it works\n",
    "query2 = \"help me with data analysis and charts\"\n",
    "\n",
    "#again lets get those searches\n",
    "results2 = collection.query(\n",
    "    query_texts=[query2],\n",
    "    n_results=3\n",
    ")\n",
    "\n",
    "\n",
    "##Now this will result in all the searches\n",
    "print(f\"Query: '{query2}'\")\n",
    "print(\"\\nMost similar past conversations:\")\n",
    "for i, (doc, distance) in enumerate(zip(results2['documents'][0], results2['distances'][0])):\n",
    "    print(f\"{i+1}. {doc}\")\n",
    "    print(f\"   Similarity score: {1-distance:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02f777b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared detailed conversation data with metadata!\n",
      "Sample metadata: ['python', 'requests', 'beautifulsoup']\n"
     ]
    }
   ],
   "source": [
    "#now lets try to add some realistic conversation\n",
    "import json\n",
    "\n",
    "#here is the detailed conversation\n",
    "detailed_conversations = [\n",
    "    {\n",
    "        \"conversation\": \"User: I'm new to Python and want to build my first web scraper. Agent: Great! Let's start with requests and BeautifulSoup libraries.\",\n",
    "        \"timestamp\": \"2024-08-28 10:30:00\",\n",
    "        \"topic\": \"web scraping\",\n",
    "        \"user_level\": \"beginner\",\n",
    "        \"technologies\": [\"python\", \"requests\", \"beautifulsoup\"]\n",
    "    },\n",
    "    {\n",
    "        \"conversation\": \"User: Can you help me understand neural networks? Agent: Sure! Neural networks are inspired by how the brain works...\",\n",
    "        \"timestamp\": \"2024-08-28 14:15:00\", \n",
    "        \"topic\": \"machine learning\",\n",
    "        \"user_level\": \"beginner\",\n",
    "        \"technologies\": [\"neural networks\", \"AI\", \"deep learning\"]\n",
    "    }\n",
    "]\n",
    "#lets try to print the data and metadata\n",
    "print(\"Prepared detailed conversation data with metadata!\")\n",
    "print(f\"Sample metadata: {detailed_conversations[0]['technologies']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09903383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 2 detailed conversations with metadata!\n",
      "Total conversations in collection: 2\n",
      "\n",
      "Sample metadata: {'technologies': '[\"python\", \"requests\", \"beautifulsoup\"]', 'user_level': 'beginner', 'timestamp': '2024-08-28 10:30:00', 'topic': 'web scraping'}\n"
     ]
    }
   ],
   "source": [
    "#now lets store all the convo in our data base chroma db with metadata also\n",
    "for i, conv_data in enumerate(detailed_conversations):\n",
    "    collection.add(\n",
    "        documents=[conv_data[\"conversation\"]],\n",
    "        metadatas=[{\n",
    "            \"timestamp\": conv_data[\"timestamp\"],\n",
    "            \"topic\": conv_data[\"topic\"],\n",
    "            \"user_level\": conv_data[\"user_level\"],\n",
    "            \"technologies\": json.dumps(conv_data[\"technologies\"])  # Convert list to JSON string\n",
    "        }],\n",
    "        ids=[f\"detailed_conv_{i+1}\"]\n",
    "    )\n",
    "\n",
    "print(f\"Added {len(detailed_conversations)} detailed conversations with metadata!\")\n",
    "print(f\"Total conversations in collection: {collection.count()}\")\n",
    "\n",
    "# Let's see  now  how this metadata looks like\n",
    "sample_result = collection.get(ids=[\"detailed_conv_1\"], include=[\"metadatas\"])\n",
    "print(f\"\\nSample metadata: {sample_result['metadatas'][0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e83429",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
